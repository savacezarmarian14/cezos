#include <kmap.h>
#include <kclock.h>
#include <types.h>
#include <mmu.h>
#include <assert.h>
#include <string.h>
#include <memlayout.h>
#include <x86.h>

typedef char byte_t;


size_t pages_count;				// Total number of physical p ages
size_t pages_basemem_count;		// base memory (in pages)

pde_t *kern_page_directory;		// Kernel page directory
struct page_status *pages;
static struct page_status *page_free_list;

static void check_page_list(int only_low_memory);
static void check_kern_pgdir(pde_t *kpgdir);
pde_t *get_page_table(pde_t *pgdir, const void *virtaddr, int create);
static void check_kern_pgdir_installed(void);

#define PAGE_ALLIGNED_ROUND(addr)										\
	(typeof(addr)) ((uint32_t)(addr) + (PAGE_SIZE - (uint32_t)(addr) % PAGE_SIZE))

#define IS_PAGE_PRESENT(page)			\
	(page & PTE_P)

#define IS_PAGE_WRITABLE(page)			\
	(page & PTE_W)

static int
vram_read(int reg)
{
	unsigned int r1, r2;
	r1 =  mc_read(reg);
	r2 = (mc_read(reg+1) << 8);
	return r1 | r2;
}

static void
get_memory_size(void)
{
	size_t basemem, extmem, ext16mem, totalmem;

	// Use read call to get available memory.
	basemem 	= vram_read(NVRAM_BASELO);
	extmem  	= vram_read(NVRAM_EXTLO);
	ext16mem 	= vram_read(NVRAM_EXT16LO) * 64;

	if (ext16mem != 0) {
		totalmem = 16 * 1024 + ext16mem;
	} else if (extmem != 0) {
		totalmem = 1  * 1024 + extmem;
	} else {
		totalmem = basemem;
	}

	pages_basemem_count = basemem / (PAGE_SIZE / 1024);
	pages_count = totalmem / (PAGE_SIZE / 1024);

	cprintf("[Info] Total memory: %u Kb\nAvailable: %u Kb\nExtended: %u Kb\n",
		totalmem, basemem, totalmem - basemem);
	cprintf("[Info] Total pages: %u\nTotal pages Available: %u\n",
		pages_count, pages_basemem_count);
}

static void *
boot_alloc(unsigned int nbytes)
{
	static byte_t *next_free = NULL;
	extern byte_t end_bss[];
	byte_t *alloc_address;

	if (next_free == NULL) {
		// Provide next free address. For that i provided end_bss variable
		// generated by the linker. This variable should point to end of bss in kern
		// Use next_free to not modify end_bss value. The address should be page alligned
		next_free = PAGE_ALLIGNED_ROUND((char *)end_bss);
	}

	if (nbytes == 0) {
		cprintf("[Info] First address to be allocated: %p\n", (void *)next_free);
		return (void *) next_free;
	}

	alloc_address = next_free;
	next_free = PAGE_ALLIGNED_ROUND(next_free + nbytes);

	if ((virtaddr_t) next_free > (KERNEL_BASE_ADDRESS + PAGE_TABLE_SIZE)) {
		MEM_ERROR_LOOP("Not enought memory\n")
	}

	cprintf("[Info] %u bytes starting from address %p is allocated\n",
		nbytes, alloc_address);

	return (void *)alloc_address;
}

static pde_t *
create_kern_pgdir(void)
{
	// This function will provide address of the first page in kernel page directory
	// This will not alloc the whole page directory insted will alloc first page
	pde_t *pgdir;

	pgdir = (pde_t *) boot_alloc(PAGE_SIZE);
	if (pgdir == NULL) {
		MEM_ERROR_LOOP("Couldn't create kernel page_directory\n");
	}
	memset(pgdir, 0, PAGE_SIZE);
	return pgdir;
}

void
init_pages(struct page_status *pages)
{
	int i;
	uint32_t used_count;
	// Mark the physical page 0 indisponible to preserve IDT and BIOS structure
	pages[0].refs = 1;
	pages[0].next_free = NULL;

	// Mark base memory as free
	for (i = 1; i < pages_basemem_count; ++i) {
		pages[i].next_free = page_free_list;
		page_free_list = &pages[i];
		pages[i].refs = 0;

#ifdef VERBOSE
		cprintf("[Info] [Verbose] Page %u set as FREE\n", i);
#endif // VERBOSE
	}

	// mark IO hole (IOPHYSMEM -> EXTPHYSMEM) as in used (it should not be allocated)
	used_count = (uint32_t) PADDR(boot_alloc(0)) / PAGE_SIZE;
	for (; i < used_count; ++i) {
		pages[i].next_free = NULL;
		pages[i].refs = 1;
#ifdef VERBOSE
		cprintf("[Info] [Verbose] Page %u set as USED\n", i);
#endif // VERBOSE

	}

	// mark extended memory as free
	for (; i < pages_count; ++i) {
		pages[i].next_free = page_free_list;
		page_free_list = &pages[i];
		pages[i].refs = 0;
#ifdef VERBOSE
		cprintf("[Info] [Verbose] Page %u set as FREE\n", i);
#endif // VERBOSE
	}
}

struct page_status *
first_free_page()
{
	struct page_status *head;

	head = page_free_list;
	page_free_list = page_free_list->next_free;

	if (head == NULL) {
		MEM_ERROR_LOOP("Not enought memory\n");
	}

	head->next_free = NULL;
	return head;
}

void
invalidate_tlb(void *vaddr)
{
	invlpg(vaddr);
}

struct page_status *
page_alloc(int alloc_flags)
{
	struct page_status *ps;
	void *vaddr = NULL;
	int should_fill_zero = 0;

	ps = first_free_page();

	should_fill_zero = (alloc_flags & PAGE_ZERO_FILLED);
	if (should_fill_zero == PAGE_ZERO_FILLED) {
		vaddr = page2kva(ps);
		memset(vaddr, 0 , PAGE_SIZE);
		cprintf("[Info] Page [%d] [%p : %p] Filled with zero\n", (PDX(vaddr) | PTX(vaddr)),
			vaddr, (char *)(vaddr + PAGE_SIZE));
	}

	return ps;
}

void
free_page(struct page_status *ps)
{
	if (ps->refs != 0 || ps->next_free != NULL) {
		MEM_ERROR_LOOP("Page still in use\n");
	}

	ps->next_free = page_free_list;
	page_free_list = ps;

	/* just to be sure */
	ps->refs = 0;
}

struct page_status *
search_page(pde_t *pgdir, void *vaddr, pte_t **store_buffer)
{
	pte_t *pte;

	pte = get_page_table(pgdir, vaddr, /* create */ 0);
	if (pte == NULL) {
		return NULL;
	}

	if (IS_PAGE_PRESENT(*pte) == 0) {
		return NULL;
	}

	if (store_buffer != NULL) {
		*store_buffer = pte;
	}

	return pa2page(PTE_ADDR(*pte));
}

void
page_decref(struct page_status* ps)
{
	ps->refs -= 1;
	if (ps->refs == 0) {
		free_page(ps);
	}
}



void
remove_page(pde_t *pgdir, void *vaddr)
{
	pte_t *pte_store = NULL;
	struct page_status *ps = search_page(pgdir, vaddr, &pte_store);
	if (ps == NULL) {
		return;
	}
	*pte_store = 0;
	page_decref(ps);
	invalidate_tlb(vaddr);
}

int
insert_page(pde_t *pgdir, struct page_status *ps, void *vaddr, int permissions)
{
	pte_t *pte;
	physaddr_t paddr;
	pte = get_page_table(pgdir, vaddr, /* create */ 1);
	if (pte == NULL) {
		cprintf("[Error] Invalid virtual address %p\n", vaddr);
		return -1;
	}

	paddr = page2pa(ps);
	if (PTE_ADDR(*pte) == paddr) {
		int obtained_perm = (*pte & 0xfff);
		if (obtained_perm = permissions) {
			return 0;
		}
		invalidate_tlb(vaddr);
		*pte = paddr | permissions | PTE_P;
		return 0;
	}

	if (IS_PAGE_PRESENT(*pte)) {
		remove_page(pgdir, vaddr);
	}

	ps->refs += 1;
	*pte = paddr | permissions | PTE_P;
	return 0;
}



// Get specific page table for address virtaddr. If create flag not 0
// than the page that virtaddr should refer is created.
pde_t *
get_page_table(pde_t *pgdir, const void *virtaddr, int create)
{
	virtaddr_t vaddr = (virtaddr_t) virtaddr;
	pde_t pde = pgdir[PDX(vaddr)];
	physaddr_t paddr;
	uint32_t perm = PTE_W | PTE_P | PTE_U;

	struct page_status *ps = NULL;

	if (IS_PAGE_PRESENT(pde) == 0 && create == 0) {
		MEM_ERROR_LOOP("Invalid virtual address\n");
	}

	if (IS_PAGE_PRESENT(pde) == 0 && create != 0) {
		ps = page_alloc(1);
		if (ps == NULL) {
			MEM_ERROR_LOOP("Couldn't allocate new page\n");
		}

		ps->refs += 1;
		pde = page2pa(ps) | perm;
		pgdir[PDX(vaddr)] = pde;
	}

	paddr = PTE_ADDR(pde);
	pde_t *pagetable_va = KADDR(paddr);
	return &pagetable_va[PTX(vaddr)];
}

/* Map virtual addresses to phys addreses */
static void
map_memory_region(pde_t *pgdir, virtaddr_t virtaddr, size_t size,
	physaddr_t physaddr, unsigned int permission)
{
	int i;
	int page_count = size / PAGE_SIZE;
	pte_t *pte = NULL;
	void *page_virtual_address = NULL;


	for (i = 0; i < page_count; ++i) {
		page_virtual_address =  (void *) (virtaddr + i * PAGE_SIZE);
		pte = get_page_table(pgdir, page_virtual_address, 1);
		if (pte == NULL) {
			MEM_ERROR_LOOP("Couldn't extract specific page table\n");

		}
		*pte = (physaddr + i * PAGE_SIZE) | permission | PTE_P ;
	}
}

void
initialize_memory(void)
{
	uint32_t cr0; // Use to store control register 0 to set up memory
	uint32_t pages_region_count;
	uint32_t remaining_mem = 0xFFFFFFFF - KERNEL_BASE_ADDRESS;
	// +1 to point exactly to the end of pa adrress

	// Detect installed memory on machine
	get_memory_size();

	kern_page_directory = create_kern_pgdir();
	*(kern_page_directory + PDX(U_VIRTUAL_PAGE_TABLE)) =
		PADDR(kern_page_directory) | PTE_U | PTE_P;

	cprintf("[Info] Kernel page directory allocated\n");

	pages = (struct page_status *)boot_alloc(pages_count * sizeof(struct page_status));
	pages_region_count = (uint32_t) boot_alloc(0) - (uint32_t) pages;
	memset(pages, 0, pages_count);

	init_pages(pages);
	check_page_list(1);
	// In order to create a real and functional page directory,
	// I have to create a boot region. First map virtual address
	// starting from U_PAGES to phys addrs starting from PADDR(pages)

	map_memory_region (kern_page_directory, /*start virt*/ U_PAGES, /*size*/PAGE_TABLE_SIZE,
		/*start phys*/PADDR(pages), PTE_U);
	cprintf("[Info] Mapped starting from virt %p and phys %p\n", U_PAGES, PADDR(pages));

	// Now i will use phys addres that bootstack refers to map a kernel stack
	map_memory_region(kern_page_directory, /*start virt*/ KERNEL_STACK_TOP - KERNEL_STACK_SIZE,
		/*size*/ PAGE_TABLE_SIZE, /*start phys*/ PADDR(bootstack), PTE_U);
	cprintf("[Info] Mapped starting from virt %p and phys %p\n",
		KERNEL_STACK_TOP - KERNEL_STACK_SIZE, PADDR(bootstack));

	// Map the rest of phys memory starting from virt KERNEL_BASE_ADDRESS and
	// phys address 0 . [KERNEL_BASE_ADDRESS, 2^32] -> [0, 2^32 - KERNEL_BASE_ADDRESS]
	map_memory_region(kern_page_directory, /*virt*/ KERNEL_BASE_ADDRESS,
		/*size*/ remaining_mem, 0, PTE_W);
	cprintf("[Info] Mapped starting from virt %p and phys %p\n",
		KERNEL_BASE_ADDRESS, 0);

	check_kern_pgdir(kern_page_directory);

	/* At this point we know for sure kernel page directory is initialized */
	lcr3(PADDR(kern_page_directory));
	cprintf("[Info] Kernel Page Directory Loaded\n");


	/* read cr0 ti initialize the rest of the bit flags of its attributes */
	cr0 = rcr0();
	cr0 |= CR0_PE | CR0_PG | CR0_AM |
		   CR0_WP | CR0_NE | CR0_MP;
	cr0 &= ~(CR0_TS | CR0_EM);
	/* load the actualized cr0 */
	lcr0(cr0);

	check_kern_pgdir_installed();
}

/* check after the kern pgdir loaded in ptbr (cr3)*/
static void
check_kern_pgdir_installed(void)
{
	struct page_status *ps, *ps0, *ps1, *ps2;
	struct page_status *aux;
	pte_t *ptep, *ptep1;
	virtaddr_t va;
	int i;


	// check that we can read and write installed pages
	ps0 = ps1 = ps2 = NULL;
	ps0 = page_alloc(0);
	ps1 = page_alloc(0);

	if (ps0 == NULL || ps1 == NULL) {
		MEM_ERROR_LOOP("page alloc returns NULL\n");
	}

	/* free alocated page */
	free_page(ps0);
	memset(page2kva(ps1), 0x01010101U, PAGE_SIZE);

	insert_page(kern_page_directory, ps1, (void*) PAGE_SIZE, PTE_W);

	if (ps1->refs != 1) {
		MEM_ERROR_LOOP("Page insert failed\n");
	}

	if (*(uint32_t *)PAGE_SIZE != 0x01010101U) {
		MEM_ERROR_LOOP("Memory corupted\n");
	}

	remove_page(kern_page_directory, page2kva(ps1));
	kern_page_directory[0] = 0;
	ps0->refs = 0;

	cprintf("[Info] Kernel page directory installed correctly \n");
}


/* Test function before initiate user space */
static void
check_page_list(int only_low_memory)
{
	struct page_status *ps, *ps1, *ps2;
	unsigned pdx_limit = only_low_memory ? 1 : NUMBER_PDENTRIES;
	int nfree_basemem = 0, nfree_extmem = 0;

	if (only_low_memory == 1) {
		struct page_status **tp[2] = { &ps1, &ps2 };
		ps = page_free_list;
		while (ps != NULL) {
			physaddr_t paddr = page2pa(ps);
			unsigned int type = PDX(paddr) >= pdx_limit;

			*tp[type] = ps;
			tp[type] = &ps->next_free;
			ps = ps->next_free;
		}
		*tp[1] = 0;
		*tp[0] = ps2;
		page_free_list = ps1;
	}

	// if there's a page that shouldn't be on the free list,
	// try to make sure it eventually causes trouble.
	ps = page_free_list;
	while (ps != NULL) {
		physaddr_t paddr = page2pa(ps);
		if (PDX(paddr) < pdx_limit) {
			void *vaddr = page2kva(ps);
			memset(vaddr, 0x97 /* Poison */, PAGE_SIZE);
		}

		ps = ps->next_free;
	}
	cprintf("[Info] Page manipulation completed\n");
}

static physaddr_t
check_va2pa(pde_t *pgdir, virtaddr_t va)
{
	pte_t *p;
	pte_t *pte;

	pte = &pgdir[PDX(va)];
	if (!(*pte & PTE_P))
		return ~0;
	p = (pte_t*) KADDR(PTE_ADDR(*pte));
	if (!(p[PTX(va)] & PTE_P))
		return ~0;
	return PTE_ADDR(p[PTX(va)]);
}


static void
check_kern_pgdir(pde_t *kpgdir)
{
	uint32_t i, n;
	uint32_t res;

	// check pages array
	n = PAGE_ALLIGNED_ROUND(pages_count * sizeof(struct page_status));
	if (n % PAGE_SIZE != 0) {
		cprintf("[Error] Not page alligned\n");
	}

	for (i = 0; i < n; i += PAGE_SIZE) {
		res = check_va2pa(kpgdir, U_PAGES + i);
		if (res != PADDR(pages) + i) {
			MEM_ERROR_LOOP("Invalid phys address in kernel page directory\n");
		}
	}

	// check phys mem
	for (i = 0; i < pages_count * PAGE_SIZE; i += PAGE_SIZE)
	{
		res = check_va2pa(kpgdir, KERNEL_BASE_ADDRESS + i);
		if (res != i) {
			MEM_ERROR_LOOP("Invalid phys address in kernel page directory\n");
		}

	}
	// check kernel stack
	for (i = 0; i < KERNEL_STACK_SIZE; i += PAGE_SIZE) {
		res = check_va2pa(kpgdir, KERNEL_STACK_TOP - KERNEL_STACK_SIZE + i);
		if (res != PADDR(bootstack) + i) {
			MEM_ERROR_LOOP("Kernel page directory initialized incorrectly\n");
		}

	}


	// check PDE permissions
	for (i = 0; i < NUMBER_PDENTRIES; i++) {
		if (i == PDX(U_VIRTUAL_PAGE_TABLE) || i == PDX(KERNEL_STACK_TOP-1) ||
				i == PDX(U_PAGES)) {
			if (IS_PAGE_PRESENT(kpgdir[i]) == 0) {
				MEM_ERROR_LOOP("Invalid permissions for page\n");
			}
		}

		if (i > PDX(KERNEL_BASE_ADDRESS)) {
			if (IS_PAGE_PRESENT(kpgdir[i]) == 0 || IS_PAGE_WRITABLE(kpgdir[i]) == 0) {
				MEM_ERROR_LOOP("Invalid permissions for page\n");
			}
		}
#ifdef VERBOSE
		cprintf("[Info] [Verbose] PDE %u persmissions checked\n", i);
#endif
	}
	cprintf("[Info] Page Directory ready\n");
}




